{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e6be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import neural_stack\n",
    "\n",
    "from neural_stack.utils import model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ca87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (32, 32)\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "NUM_LAYERS = 6\n",
    "NUM_HEADS = 8\n",
    "EMBED_DIM = 512\n",
    "PATCH_SIZE = 4\n",
    "MLP_RATIO = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18686474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n",
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::layer_norm encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n",
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Size 4x4, Total Patches=64; #params=18975234; #flops=1256365568; #activations=2232370\n",
      "| module                                 | #parameters or shape   | #flops     | #activations   |\n",
      "|:---------------------------------------|:-----------------------|:-----------|:---------------|\n",
      "| model                                  | 18.975M                | 1.256G     | 2.232M         |\n",
      "|  patch_embedding                       |  58.88K                |  1.573M    |  32.768K       |\n",
      "|   patch_embedding.pos_embedding        |   (1, 65, 512)         |            |                |\n",
      "|   patch_embedding.cls_token            |   (1, 1, 512)          |            |                |\n",
      "|   patch_embedding.proj                 |   25.088K              |   1.573M   |   32.768K      |\n",
      "|    patch_embedding.proj.weight         |    (512, 3, 4, 4)      |            |                |\n",
      "|    patch_embedding.proj.bias           |    (512,)              |            |                |\n",
      "|  transformer_stack                     |  18.914M               |  1.255G    |  2.2M          |\n",
      "|   transformer_stack.0                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.0.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.0.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.0.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.0.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|   transformer_stack.1                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.1.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.1.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.1.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.1.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|   transformer_stack.2                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.2.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.2.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.2.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.2.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|   transformer_stack.3                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.3.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.3.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.3.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.3.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|   transformer_stack.4                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.4.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.4.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.4.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.4.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|   transformer_stack.5                  |   3.152M               |   0.209G   |   0.367M       |\n",
      "|    transformer_stack.5.layer_norm_1    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.5.msa             |    1.051M              |    72.484M |    0.2M        |\n",
      "|    transformer_stack.5.layer_norm_2    |    1.024K              |    0.166M  |    0           |\n",
      "|    transformer_stack.5.mlp_block.block |    2.1M                |    0.136G  |    0.166M      |\n",
      "|  classification_head                   |  2.05K                 |  3.584K    |  2             |\n",
      "|   classification_head.0                |   1.024K               |   2.56K    |   0            |\n",
      "|    classification_head.0.weight        |    (512,)              |            |                |\n",
      "|    classification_head.0.bias          |    (512,)              |            |                |\n",
      "|   classification_head.2                |   1.026K               |   1.024K   |   2            |\n",
      "|    classification_head.2.weight        |    (2, 512)            |            |                |\n",
      "|    classification_head.2.bias          |    (2,)                |            |                |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::layer_norm encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n",
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Size 8x8, Total Patches=16; #params=19024386; #flops=324738560; #activations=544306\n",
      "| module                                 | #parameters or shape   | #flops     | #activations   |\n",
      "|:---------------------------------------|:-----------------------|:-----------|:---------------|\n",
      "| model                                  | 19.024M                | 0.325G     | 0.544M         |\n",
      "|  patch_embedding                       |  0.108M                |  1.573M    |  8.192K        |\n",
      "|   patch_embedding.pos_embedding        |   (1, 17, 512)         |            |                |\n",
      "|   patch_embedding.cls_token            |   (1, 1, 512)          |            |                |\n",
      "|   patch_embedding.proj                 |   98.816K              |   1.573M   |   8.192K       |\n",
      "|    patch_embedding.proj.weight         |    (512, 3, 8, 8)      |            |                |\n",
      "|    patch_embedding.proj.bias           |    (512,)              |            |                |\n",
      "|  transformer_stack                     |  18.914M               |  0.323G    |  0.536M        |\n",
      "|   transformer_stack.0                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.0.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.0.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.0.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.0.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|   transformer_stack.1                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.1.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.1.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.1.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.1.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|   transformer_stack.2                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.2.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.2.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.2.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.2.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|   transformer_stack.3                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.3.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.3.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.3.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.3.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|   transformer_stack.4                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.4.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.4.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.4.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.4.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|   transformer_stack.5                  |   3.152M               |   53.86M   |   89.352K      |\n",
      "|    transformer_stack.5.layer_norm_1    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.5.msa             |    1.051M              |    18.122M |    45.832K     |\n",
      "|    transformer_stack.5.layer_norm_2    |    1.024K              |    43.52K  |    0           |\n",
      "|    transformer_stack.5.mlp_block.block |    2.1M                |    35.652M |    43.52K      |\n",
      "|  classification_head                   |  2.05K                 |  3.584K    |  2             |\n",
      "|   classification_head.0                |   1.024K               |   2.56K    |   0            |\n",
      "|    classification_head.0.weight        |    (512,)              |            |                |\n",
      "|    classification_head.0.bias          |    (512,)              |            |                |\n",
      "|   classification_head.2                |   1.026K               |   1.024K   |   2            |\n",
      "|    classification_head.2.weight        |    (2, 512)            |            |                |\n",
      "|    classification_head.2.bias          |    (2,)                |            |                |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::layer_norm encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Size 16x16, Total Patches=4; #params=19313154; #flops=96255488; #activations=156850\n",
      "| module                                 | #parameters or shape   | #flops     | #activations   |\n",
      "|:---------------------------------------|:-----------------------|:-----------|:---------------|\n",
      "| model                                  | 19.313M                | 96.255M    | 0.157M         |\n",
      "|  patch_embedding                       |  0.397M                |  1.573M    |  2.048K        |\n",
      "|   patch_embedding.pos_embedding        |   (1, 5, 512)          |            |                |\n",
      "|   patch_embedding.cls_token            |   (1, 1, 512)          |            |                |\n",
      "|   patch_embedding.proj                 |   0.394M               |   1.573M   |   2.048K       |\n",
      "|    patch_embedding.proj.weight         |    (512, 3, 16, 16)    |            |                |\n",
      "|    patch_embedding.proj.bias           |    (512,)              |            |                |\n",
      "|  transformer_stack                     |  18.914M               |  94.679M   |  0.155M        |\n",
      "|   transformer_stack.0                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.0.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.0.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.0.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.0.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|   transformer_stack.1                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.1.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.1.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.1.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.1.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|   transformer_stack.2                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.2.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.2.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.2.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.2.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|   transformer_stack.3                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.3.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.3.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.3.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.3.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|   transformer_stack.4                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.4.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.4.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.4.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.4.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|   transformer_stack.5                  |   3.152M               |   15.78M   |   25.8K        |\n",
      "|    transformer_stack.5.layer_norm_1    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.5.msa             |    1.051M              |    5.268M  |    13K         |\n",
      "|    transformer_stack.5.layer_norm_2    |    1.024K              |    12.8K   |    0           |\n",
      "|    transformer_stack.5.mlp_block.block |    2.1M                |    10.486M |    12.8K       |\n",
      "|  classification_head                   |  2.05K                 |  3.584K    |  2             |\n",
      "|   classification_head.0                |   1.024K               |   2.56K    |   0            |\n",
      "|    classification_head.0.weight        |    (512,)              |            |                |\n",
      "|    classification_head.0.bias          |    (512,)              |            |                |\n",
      "|   classification_head.2                |   1.026K               |   1.024K   |   2            |\n",
      "|    classification_head.2.weight        |    (2, 512)            |            |                |\n",
      "|    classification_head.2.bias          |    (2,)                |            |                |\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn((1, NUM_CHANNELS, *IMAGE_SIZE))\n",
    "\n",
    "for patch_size in [4, 8, 16]:\n",
    "    vit_model = neural_stack.vision_transformer.VisionTransformer(\n",
    "        img_size=IMAGE_SIZE,\n",
    "        patch_size=patch_size,\n",
    "        in_channels=NUM_CHANNELS,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        mlp_ratio=MLP_RATIO,\n",
    "        dropout=0.1,\n",
    "        num_classes=2\n",
    "    )\n",
    "\n",
    "    num_params, num_flops, num_acts, summary = model_summary(vit_model, dummy_input)\n",
    "    num_patches = IMAGE_SIZE[0] * IMAGE_SIZE[1] // (patch_size ** 2)\n",
    "    print(f\"Patch Size {patch_size}x{patch_size}, Total Patches={num_patches}; #params={num_params}; #flops={num_flops}; #activations={num_acts}\")\n",
    "    print(summary)\n",
    "\n",
    "    del vit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a07f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
